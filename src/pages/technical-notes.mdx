---
layout: '../layouts/BaseLayout.astro'
title: 'Technical Notes — Echoes of Indiana'
---

import NavBar from '../components/NavBar.astro';

<NavBar />

<div class="max-w-4xl mx-auto px-4 py-16">

# Technical Implementation Notes

*Internal development documentation and pipeline specifications*

---

## Conversational Video Pipeline (Option 2 + Smart Clip Router)

**Goal:** Real-time feeling, high visual fidelity. We mix pre-rendered "hero" clips with live lipsynced talk loops.

### States
`IDLE → SUMMON → TALK → OUTRO (+ GLITCH when needed)`

- **IDLE** – 20–30 s loop: breathing/blinking head, slow particles.
- **SUMMON** – 2–3 s burst: particles rush in, head forms on the bookend pose.
- **TALK**
  - **FAQ match** (prebaked clip: audio + video) → instant play.
  - **Else live**: LLM → TTS → Wav2Lip-on-mouth over a neutral loop (4/6/8/12 s).
- **OUTRO** – 1–2 s dissolve: head → particles → black.
- **GLITCH** – 1 s loop: frozen frame + RGB offset/datamosh to cover stalls.

### Clip Library (per persona)

| Type            | Count | Lengths (s) | Notes                              |
|-----------------|-------|-------------|-------------------------------------|
| Idle loops      | 2–3   | 20–30       | Micro-motion only                   |
| Talk bases      | 6–10  | 4/6/8/12    | Neutral face motion, bookend pose   |
| Summons         | 2–3   | 2–3         | Particles → head                    |
| Outros          | 2–3   | 1–2         | Head → particles                    |
| Glitch masks    | 2–3   | 1 (loop)    | For >2 s latency spikes             |
| Accent bursts   | 2–3   | 0.5–1       | Persona color/shape flourishes      |
| FAQ hero clips  | 30–50 | variable    | Full animation + baked audio        |

**Bookend pose:** Every clip starts/ends on the same still frame (12–16 frames) for clean cuts.

### Router Logic (pseudo)

```python
q = transcribe(audio)
vec = embed(q)
hit = faiss.search(vec, top_k=1)

if hit.score > 0.83 and cooldown_ok(hit.id):
    play_clip(hit.clip_path)          # Prebaked FAQ
else:
    answer = llm(q, persona)
    wav = tts(answer)
    base = choose_loop(len(wav))       # 4/6/8/12 s
    talk = wav2lip(base, wav, roi="mouth")
    play_clip(talk)
```

### File Format

- **Canvas:** 3840×2160, with a 2160×2160 square action-safe centered.
- **Codec:** ProRes 4444 (alpha) or ProRes 422 HQ on black; HAP-Q in TouchDesigner.
- **Blacks crushed to 0–2%.** Add light grain to kill banding.

### Latency Budget

- **STT + LLM + TTS:** ~0.4–0.7 s (fast path).
- **Wav2Lip mouth pass:** ~2–3 s for 6–8 s chunk on a 4090.
- **Mask anything above ~2 s** with GLITCH or "ruminating…" particle loop.

### To-Do

1. **Draft FAQ list + canonical answers** (30–50 per persona).
2. **Generate particle packs and all state clips** (bookend pose locked).
3. **Build router microservice** (embeddings + FAISS).
4. **Integrate Wav2Lip/GeneFace++ ROI pipeline.**
5. **Wire TouchDesigner/Resolume state machine** (OSC/HTTP triggers).
6. **Test end-to-end latency,** add missing FAQs from logs.

---

## Development Pipeline Notes

### Content Production Workflow

**Asset Generation Priority:**
1. Vonnegut persona pack (primary launch target)
2. Default Oracle baseline interactions
3. FAQ library expansion based on user logs

**Technical Stack Integration:**
- TouchDesigner for real-time compositing and state management
- FAISS vector database for FAQ matching
- Wav2Lip for real-time mouth synchronization
- ProRes pipeline for maximum quality preservation

### Performance Optimization

**GPU Requirements:**
- RTX 4090 or equivalent for real-time Wav2Lip processing
- Dedicated VRAM allocation for clip buffering
- Hardware-accelerated video decode/encode pipeline

**Fallback Strategies:**
- Pre-rendered FAQ clips eliminate processing delays
- Glitch state masks technical limitations
- Graceful degradation for lower-end hardware

---

## Integration Notes

This pipeline connects to the main Pepper's Ghost installation described in the [implementation strategy](/implementation) and [technical specifications](/peppers-ghost-spec). The conversational system operates independently of the display technology choice, allowing flexibility in deployment scenarios.

### Cross-Reference
- [Full Implementation Strategy](/implementation)
- [Pepper's Ghost Technical Specifications](/peppers-ghost-spec)
- [Project Budget & Timeline](/budget)

---

## Clip Library JSON Schema

Schema definition for the Oracle clip library system. This schema validates all clip metadata entries to ensure consistency across the content pipeline.

```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "title": "OracleClip",
  "type": "object",
  "properties": {
    "id": { "type": "string" },
    "persona": { "type": "string" },
    "type": { "type": "string", "enum": ["idle","summon","talk_base","outro","glitch","accent","faq"] },
    "duration": { "type": "number" },
    "emotion": { "type": "string" },
    "path": { "type": "string" },
    "bookend": { "type": "boolean", "default": true },
    "cooldown": { "type": "number", "description": "seconds before reuse allowed" },
    "tags": { "type": "array", "items": { "type": "string" } }
  },
  "required": ["id","persona","type","duration","path"]
}
```

### Schema Usage

This schema defines the structure for all video clips in the Oracle system:
- **id**: Unique identifier for the clip
- **persona**: Which Oracle persona (Vonnegut, Default, etc.)
- **type**: Clip category matching state machine requirements
- **duration**: Length in seconds
- **emotion**: Optional emotional state for context-aware selection
- **path**: File system or CDN path to video asset
- **bookend**: Whether clip uses standard start/end frames for seamless transitions
- **cooldown**: Minimum seconds before clip can be replayed
- **tags**: Additional metadata for enhanced routing decisions

The schema file is also available at [`/spec/clip_schema.json`](/spec/clip_schema.json) for direct integration with validation tools.

---

## Visual Pipeline Demo

<div class="relative my-8">
  <div class="aspect-video rounded-lg overflow-hidden shadow-lg bg-black">
    <iframe 
      src="https://www.youtube.com/embed/hjK92tJcdF0?autoplay=0&mute=0&loop=0&controls=1&showinfo=1&rel=0&iv_load_policy=3&modestbranding=1&playsinline=1"
      class="w-full h-full"
      style="border: none;"
      allow="autoplay; encrypted-media"
      allowfullscreen>
    </iframe>
  </div>
  
  <p class="text-center text-sm text-gray-400 mt-4">
    <strong>Particle Consolidation Demo</strong> — Demonstration of particles consolidating to form a persona, then dispersing back to neutral/idle particle animation. This represents the SUMMON and OUTRO states in the pipeline.
  </p>
</div>

This demo illustrates the core visual transformation of the Oracle Entity system:
- **Particle Consolidation**: Ambient particles coalesce to form the Oracle persona
- **Persona Materialization**: The gradual formation of a recognizable entity from particle chaos
- **Dissolution Effect**: The persona disperses back into neutral particle state
- **Idle State**: Continuous ambient particle movement between interactions

### Additional Pipeline Demonstration

<div class="relative my-8">
  <div class="aspect-video rounded-lg overflow-hidden shadow-lg bg-black">
    <iframe 
      src="https://www.youtube.com/embed/WxDaEPDh72M?autoplay=0&mute=0&loop=0&controls=1&showinfo=1&rel=0&iv_load_policy=3&modestbranding=1&playsinline=1"
      class="w-full h-full"
      style="border: none;"
      allow="autoplay; encrypted-media"
      allowfullscreen>
    </iframe>
  </div>
  
  <p class="text-center text-sm text-gray-400 mt-4">
    <strong>Extended Particle System Demo</strong> — Additional footage showing particle behavior and system variations for the Oracle Entity pipeline.
  </p>
</div>

---

## Recommended Implementation Updates

*Based on recent technical discussions, here are key updates to consider for the implementation approach:*

### 1. Simplified Technical Pipeline

**States:**
`IDLE → SUMMON → TALK → OUTRO (+ GLITCH when needed)`

**TALK Options:**
- FAQ match → instant prebaked clip playback (no processing)
- Live response → Audio-amplitude particle modulation
- Optional future: Lip-sync for photorealistic personas only

**Particle Animation Pipeline:**
- Base: Pre-rendered particle face videos (4/6/8/12s loops)
- Enhancement: Real-time audio-reactive particle overlay
- Mouth region responds to speech amplitude/frequency
- Persona-specific particle behaviors (smoke, stars, data points)

### 2. Technology Stack Additions

**Add:**
- Video generation tools (RunwayML, Pika, Stable Video)
- Simplified playback options (Resolume/QLab)
- WebSocket voice pipeline (replace button-based description)
- Particle systems as primary character representation

**Downplay:**
- Heavy emphasis on Wav2Lip processing times
- Complex facial landmark tracking

### 3. Budget Reallocation

**Reallocate:**
- Less: "Wav2Lip optimization" → More: "Particle system development"
- Less: "Facial tracking hardware" → More: "Premium projection equipment"
- Add: "AI video generation tools subscription" (~$200/month)
- Add: "Technical collaborator/TD" (part-time, 3-6 months)

### 4. Updated Phase 1 Implementation

**Months 1-2: Foundation**
- Generate particle-based persona videos using AI tools
- Implement WebSocket voice conversation pipeline
- Set up simple video playback system (Resolume/QLab)
- Expand FAQ library from visitor interactions

### 5. Particle Design Language

Each Oracle persona has a unique particle signature:

#### Base System
- Primary particles: Cyan/teal energy motes (#00CED1)
- Accent particles: Golden wisdom sparks (#FFD700)
- Behavior: Constant drift, responsive to breath and speech
- Density: Variable based on audio amplitude and emotion

#### Persona Signatures
- **Vonnegut**: Cigarette smoke wisps, typewriter characters
- **Indiana Sage**: Limestone dust, corn pollen
- **Lil Bub**: Iridescent stars, rainbow shifts
- **Kinsey**: Data points, graph elements
- **Madame Walker**: Art Deco gold flourishes, hair product molecules
- **Lettie Vance**: Fashion fabric swatches, pattern fragments

### 6. Artistic Rationale

**"Why Particles?"**

Oracle entities manifest as living constellations of light particles rather than photorealistic faces. This aesthetic choice:
- Creates a more magical, ethereal presence
- Aligns with the "echoes" theme - memories as fragments
- Is technically forgiving while allowing real-time audio reactivity
- Suggests consciousness emerging from quantum possibility

### 7. Simplified Response Times

**Response Times:**
- FAQ match: Instant (&lt;100ms)
- Live generation: 2-3 seconds (masked by SUMMON animation)
- Particle reactivity: Real-time (audio-driven)

### 8. Updated Experience Description

*Consider updating visitor-facing descriptions to:*

"The Entity responds through directional speakers, their particle form pulsing and flowing with the rhythm of speech, occasionally coalescing into clearer features during profound moments"

### 9. Collaboration Opportunities

**Seeking Technical Collaborator:**
- TouchDesigner/Resolume experience
- Installation art background
- Audio-reactive visual systems
- Part-time, project-based (3-6 months)

### 10. Simplified Technical Flow

```
Audio Input → Speech-to-Text → FAQ Matching/LLM
     ↓                              ↓
Particle Modulation ← Video Selection ← Response
```

**Key Insight:** Pre-rendered FAQ responses eliminate 80% of processing time, enabling instant playback of high-quality interactions. Only truly novel questions require live generation.

### Implementation Notes

The main goal: Shift the narrative from "complex technical challenge" to "artistic choice that happens to be technically smart." The particle approach isn't a compromise—it's a more magical solution than photorealism would be.

</div>